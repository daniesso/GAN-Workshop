{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN workshop 1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPC2sYyBTCMOVnNRx8d5akJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"D1FLtjuBJUg2"},"source":["import tensorflow as tf\n","from tensorflow.keras import layers, Sequential, losses, metrics, activations\n","from tensorflow.keras.datasets import mnist\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hAZAMhxBPfd_"},"source":["def normalize(x):\n","  # Normalizes to [-1, 1]\n","  return (x - 127.5) / 127.5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4rHAGYVeJ5cW"},"source":["# Loads data for MNIST\n","\n","BATCH_SIZE = 64\n","\n","(x_train, y_train), (x_validation, y_validation) = mnist.load_data()\n","\n","x_validation, y_validation = x_validation[:500], y_validation[:500]\n","\n","x_train, x_validation = normalize(x_train), normalize(x_validation)\n","\n","x_train, x_validation = np.reshape(x_train, (x_train.shape[0], -1)), np.reshape(x_validation, (x_validation.shape[0], -1))\n","\n","dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)) \\\n","         .shuffle(buffer_size = 50_000) \\\n","         .batch(BATCH_SIZE, drop_remainder=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6l_CYJcDQzPG"},"source":["# Klassifisering"]},{"cell_type":"code","metadata":{"id":"O1hAo2i0J_ex"},"source":["# Oppvarming\n","# Definer en classifier-modell for MNIST. Denne arkitekturen kan du enkelt gjøre\n","# om til discriminator-modell senere ved å endre antall outputs fra 10 til 1.\n","#\n","# Bruk et enkelt nevralt nettverk her (ikke CNNs). \n","#\n","# Sikt gjerne på minst 97 % validation accuracy.\n","\n","classifier = None\n","\n","classifier.compile(metrics = [metrics.SparseCategoricalAccuracy()])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dnY8oDuCGJxO"},"source":["# Her hadde det desidert enkleste vært å trene classifier-modellen med \n","# classifier.fit(). I stedet demonstreres hvordan man kan trene\n","# modellen ved hjelp av det funksjonelle API-et til Tensorflow. Dette API-et\n","# blir nyttig med en gang man skal ha et mer kompliserte treningssteg, slik som \n","# for GAN. \n","#\n","# Her brukes en GradientTape for å overvåke utregningen som inngår under tape-\n","# uttrykket (forward pass gjennom modellen). Deretter kan man hente ut \n","# gradientene for en utregning Y med hensyn til variablene W, og bruke \n","# gradientene til å oppdatere modellen som vanlig (med apply_gradients). \n","\n","classification_optimizer = tf.keras.optimizers.Adam()\n","\n","@tf.function\n","def train_step_classifier(batch_x, batch_y):\n","  with tf.GradientTape() as tape:\n","\n","    output = classifier(batch_x)\n","\n","    loss = 0 # TODO \n","\n","  gradients = tape.gradient(loss, classifier.trainable_variables)\n","  classification_optimizer.apply_gradients(zip(gradients, classifier.trainable_variables))\n","\n","  return loss,  \n","\n","\n","validation_accuracy = []\n","for epoch in range(10):\n","  \n","  print(\"Epoch\", epoch)\n","  for (batch_x, batch_y) in dataset:\n","    train_step_classifier(batch_x, batch_y)\n","  \n","  accuracy = classifier.evaluate(x_validation, y_validation)[1]\n","  validation_accuracy.append(accuracy)\n","\n","plt.plot(validation_accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3FRFuCwJNWQM"},"source":["# General Adverserial Networks"]},{"cell_type":"code","metadata":{"id":"JqPPgnV2WMW2"},"source":["# Definer diskriminator-modellen. I motsetning til klassifikatoren skal denne gi\n","# ut én output-verdi: hvor vidt bilde-input-en er autentisk (true) eller \n","# generert (false). \n","\n","discriminator = None\n","\n","discriminator.compile()\n","discriminator.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A_K2GYLaX5iL"},"source":["noise_dim = 20\n","\n","# Definer generator-modellen. Denne skal ta inn en støy-vektor (en vektor med \n","# størrelse lik noise_dim av tilfeldige flyttall) og gi ut et bilde. For MNIST\n","# må den dermed ha 28*28=784 outputs. \n","#\n","# Du velger størrelsen på noise_dim selv. \n","\n","generator = None\n","\n","generator.compile()\n","generator.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4AXP2au1ah7A"},"source":["def to_image(img):\n","  return img.reshape([28, 28])\n","\n","def show_image(img):\n","  img = to_image(img)\n","  plt.imshow(img, cmap='gray')\n","  plt.show()\n","\n","def generate_noise(dim, batch_size = 1):\n","  return tf.random.normal([batch_size, dim])\n","\n","# Generer og viser et bilde fra den utrente generatoren\n","\n","generated_image = generator(generate_noise(noise_dim)).numpy()\n","\n","show_image(generated_image)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JpUlBPY9by-R"},"source":["# Implementer treningssteget. Denne tar inn én batch med treningsbilder.\n","# Denne skal generere et sett med falske bilder. Diskriminatoren skal vurdere\n","# både de falske og de ekte bildesettene. Begge modellene skal oppdateres\n","# ut fra vurderingen til diskriminatoren.\n","#\n","# Tips: bruk gjerne en Optimizer for hver av generator-modellen og diskriminator-\n","# modellen.\n","#\n","# Returnerer: \n","# D_loss: loss-verdien for diskriminatoren\n","# G_loss: loss-verdien for generatoren\n","# P_real: Diskriminatoren sin accuracy for ekte bilder\n","# P_fake: Diskriminatoren sin accuracy for falske bilder\n","\n","@tf.function\n","def train_step(real_images):\n","  \n","  D_loss = None\n","  G_loss = None\n","  P_real = None\n","  P_fake = None\n","\n","  return D_loss, G_loss, P_real, P_fake\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eXX3QeVm9OKQ"},"source":["def show_image_grid(images):\n","  N = images.shape[0]\n","\n","  fig = plt.figure(figsize=(3, 3))\n","  fig.set_size_inches(10, 10)\n","\n","  for i in range(N):\n","      plt.subplot(3, 3, i+1)\n","      img = to_image(images[i])\n","      plt.imshow(img, cmap=\"gray\")\n","      plt.axis('off')\n","\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cKTwskvcfuuU"},"source":["EPOCHS = 100\n","\n","noise_for_training_visualization = generate_noise(noise_dim, batch_size = 9)\n","\n","for epoch in range(EPOCHS):\n","\n","  print(\"Epoch\", epoch),\n","\n","  for step, (x_train, _) in enumerate(dataset):\n","    Ld, Lg, Pr, Pf = train_step(x_train)\n","\n","    if step % 100 == 0:\n","      print(\"Step {}. Ld={}, Lg=={}, Pr={}, Pf={}\".format(step, Ld, Lg, Pr, Pf))\n","\n","  show_image_grid(generator(noise_for_training_visualization).numpy())\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E2eXD3svxD_z"},"source":["# Denne kan du bruke til å utforske generatoren!\n","\n","from ipywidgets import interact\n","\n","p1 = generate_noise(noise_dim)\n","p2 = generate_noise(noise_dim)\n","p3 = generate_noise(noise_dim)\n","\n","@interact(k1=(0, 1.0), k2=(0, 1.0))\n","def g(k1, k2):\n","    p = p1 + k1 * (p2 - p1) + k2 * (p3 - p1)\n","    show_image(generator(p).numpy())"],"execution_count":null,"outputs":[]}]}
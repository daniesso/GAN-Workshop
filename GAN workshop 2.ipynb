{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN workshop 2.ipynb","provenance":[{"file_id":"1SIbjPAilpeiQ-jVPKnArUdBcHAv2D3V3","timestamp":1629921525328}],"collapsed_sections":[],"authorship_tag":"ABX9TyNaO2WOjQoQs3qh4/DyvgLm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"D1FLtjuBJUg2"},"source":["import tensorflow as tf\n","from tensorflow.keras import layers, Sequential, losses, metrics, activations\n","from tensorflow.keras.datasets import mnist\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hAZAMhxBPfd_"},"source":["def normalize(x):\n","  # Normalizes to [-1, 1]\n","  return (x - 127.5) / 127.5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4rHAGYVeJ5cW"},"source":["# Loads data for MNIST\n","\n","BATCH_SIZE = 64\n","\n","(x_train, y_train), (x_validation, y_validation) = mnist.load_data()\n","\n","x_validation, y_validation = x_validation[:500], y_validation[:500]\n","\n","x_train, x_validation = normalize(x_train), normalize(x_validation)\n","\n","x_train, x_validation = np.reshape(x_train, (x_train.shape[0], -1)), np.reshape(x_validation, (x_validation.shape[0], -1))\n","\n","dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)) \\\n","         .shuffle(buffer_size = 50_000) \\\n","         .batch(BATCH_SIZE, drop_remainder=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t3n5C8Ah5qHb"},"source":["# Prinsipper fra DCGAN:\n","# - Ikke bruk pooling: bruk i stedet konvolusjonelle lag med strides\n","# - Ikke bruk hidden dense lag (bruk altså bare konvolusjonelle lag i hidden lagene)\n","# - Bruk batch normalization etter hvert lag, utenom output-laget\n","#   til generatoren og input-laget til diskriminatoren\n","# - Bruk ReLU-aktivering for generatoren, med tanh i output-lag (jeg opplevde\n","#   imidlertid bedre resultater med LeakyReLU også for generatoren)\n","# - Bruk LeakyReLU-aktivering for diskrimatoren "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JqPPgnV2WMW2"},"source":["# Definer diskriminator-modellen fra DCGAN-arkitekturen. Denne baserer seg på\n","# Conv2D-lag. \n","\n","discriminator = None\n","\n","discriminator.compile()\n","discriminator.summary()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A_K2GYLaX5iL"},"source":["noise_dim = 20\n","\n","# Definer generator-modellen fra DCGAN-arkitekturen. Denne baserer seg på\n","# Conv2DTranspose-lag.\n","\n","generator = None\n","\n","generator.compile(loss = losses.BinaryCrossentropy(from_logits = True))\n","generator.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4AXP2au1ah7A"},"source":["def to_image(img):\n","  return img.reshape([28, 28])\n","\n","def show_image(img):\n","  img = to_image(img)\n","  plt.imshow(img, cmap='gray')\n","  plt.show()\n","\n","def generate_noise(dim, batch_size = 1):\n","  return tf.random.normal([batch_size, dim])\n","\n","# Generer og viser et bilde fra den utrente generatoren\n","\n","generated_image = generator(generate_noise(noise_dim)).numpy()\n","\n","show_image(generated_image)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JpUlBPY9by-R"},"source":["# Her kan du bruke samme train_step som i forrige notebook\n","\n","@tf.function\n","def train_step(real_images):\n","  \n","  D_loss = None\n","  G_loss = None\n","  P_real = None\n","  P_fake = None\n","\n","  return D_loss, G_loss, P_real, P_fake\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5v62sqeGBKQx"},"source":["def show_image_grid(images):\n","  N = images.shape[0]\n","\n","  fig = plt.figure(figsize=(3, 3))\n","  fig.set_size_inches(10, 10)\n","\n","  for i in range(N):\n","      plt.subplot(3, 3, i+1)\n","      img = to_image(images[i])\n","      plt.imshow(img, cmap=\"gray\")\n","      plt.axis('off')\n","\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cKTwskvcfuuU"},"source":["EPOCHS = 20\n","\n","noise_for_training_visualization = generate_noise(noise_dim, batch_size = 9)\n","\n","for epoch in range(EPOCHS):\n","\n","  print(\"Epoch\", epoch),\n","\n","  for step, (x_train, _) in enumerate(dataset):\n","    Ld, Lg, Pr, Pf = train_step(x_train)\n","\n","    if step % 100 == 0:\n","      print(\"Step {}. Ld={}, Lg={}, Pr={}, Pf={}\".format(step, Ld, Lg, Pr, Pf))\n","\n","  show_image_grid(generator(noise_for_training_visualization).numpy())\n","\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E2eXD3svxD_z"},"source":["# Denne kan du bruke til å utforske generatoren!\n","\n","from ipywidgets import interact\n","\n","p1 = generate_noise(noise_dim)\n","p2 = generate_noise(noise_dim)\n","p3 = generate_noise(noise_dim)\n","\n","@interact(k1=(0, 1.0), k2=(0, 1.0))\n","def g(k1, k2):\n","    p = p1 + k1 * (p2 - p1) + k2 * (p3 - p1)\n","    show_image(generator(p).numpy())"],"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN workshop 3 - ansikter.ipynb","provenance":[{"file_id":"1SIbjPAilpeiQ-jVPKnArUdBcHAv2D3V3","timestamp":1629921525328}],"collapsed_sections":[],"authorship_tag":"ABX9TyMgbg1hm/jiCEnFyTcrfW6p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"D1FLtjuBJUg2"},"source":["import tensorflow as tf\n","from tensorflow.keras import layers, Sequential, losses, metrics, activations\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y3L4QKZFFz9f"},"source":["with open(\"download-cats\", \"w\") as f:\n","  f.write(\"\"\"\n","  if [ ! -d FACES128x128 ]; then\n","    wget \"https://www.dropbox.com/s/mm1bwgfk65cxtv3/FACES128x128.zip?dl=1\" -O \"FACES128x128.zip\"\n","    unzip \"FACES128x128.zip\" > /dev/null\n","    rm \"FACES128x128.zip\"\n","  fi\n","  \"\"\")\n","!bash download-cats"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yo_R__HRGfOe"},"source":[" def normalize(x):\n","  # Normalizes to [-1, 1]\n","  return (x - 127.5) / 127.5\n","\n"," def load_image(path, size = None):\n","  image = tf.io.read_file(path)\n","  image = tf.image.decode_jpeg(image)\n","  image = tf.cast(image, tf.float32)\n","  image = tf.reshape(image, [128, 128, 3])\n","  image = normalize(image)\n","  if size is not None:\n","    image = tf.image.resize(image, (size, size))\n","\n","  return image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4rHAGYVeJ5cW"},"source":["TRAINING_SET_SIZE = 10_000\n","BATCH_SIZE = 64\n","IMAGE_SIZE = 64 # Max 128\n","\n","dataset = tf.data.Dataset.list_files(\"FACES128x128/*.jpg\")\n","dataset = dataset \\\n","    .map(lambda path: load_image(path, IMAGE_SIZE), num_parallel_calls=tf.data.experimental.AUTOTUNE) \\\n","    .shuffle(buffer_size = 50_000) \\\n","    .batch(BATCH_SIZE, drop_remainder=True)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3r4kXm1oJ1aR"},"source":["def to_image(img):\n","  img = img.reshape([IMAGE_SIZE, IMAGE_SIZE, 3])\n","  img = img * 127.5 + 127.5\n","  img = img.astype(\"uint8\")\n","  return img\n","\n","def show_image(img):\n","  img = to_image(img)\n","  plt.imshow(img)\n","  plt.show()\n","\n","sample = next(iter(dataset)).numpy()[0]\n","show_image(sample)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JqPPgnV2WMW2"},"source":["# Definer diskriminator-modellen. I motsetning til klassifikatoren skal denne gi\n","# ut én output-verdi: hvor vidt bilde-input-en er autentisk (true) eller \n","# generert (false). \n","\n","discriminator = None\n","\n","discriminator.compile(loss = losses.BinaryCrossentropy(from_logits=True))\n","discriminator.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A_K2GYLaX5iL"},"source":["noise_dim = 100\n","\n","# Definer generator-modellen. Denne skal ta inn en støy-vektor (en vektor med \n","# størrelse lik noise_dim av tilfeldige flyttall) og gi ut et bilde.\n","\n","generator = None\n","\n","generator.compile(loss = losses.BinaryCrossentropy(from_logits = True))\n","generator.summary()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4AXP2au1ah7A"},"source":["def generate_noise(dim, batch_size = 1):\n","  return tf.random.normal([batch_size, dim])\n","\n","# Generer og viser et bilde fra den utrente generatoren\n","\n","generated_image = generator(generate_noise(noise_dim)).numpy()\n","\n","show_image(generated_image)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JpUlBPY9by-R"},"source":["# Her kan du bruke samme train_step som i forrige notebook\n","\n","@tf.function\n","def train_step(real_images):\n","  \n","  D_loss = None\n","  G_loss = None\n","  P_real = None\n","  P_fake = None\n","\n","  return D_loss, G_loss, P_real, P_fake\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lk32ZoxVE4Ln"},"source":["def show_image_grid(images):\n","  N = images.shape[0]\n","\n","  fig = plt.figure(figsize=(3, 3))\n","  fig.set_size_inches(10, 10)\n","\n","  for i in range(N):\n","      plt.subplot(3, 3, i+1)\n","      img = to_image(images[i])\n","      plt.imshow(img)\n","      plt.axis('off')\n","\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GZppx5Y0oz8C"},"source":["# Tips og triks\n","#\n","# Er diskriminatoren mye sterkere enn generatoren (dette ser du hvis \n","# diskriminatoren konsekvent vurderer både ekte og falske bilder med\n","# høy treffsikkerhet)?\n","# - Kan f.eks. kompensere med en lavere learning rate for diskriminatoren. "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cKTwskvcfuuU"},"source":["EPOCHS = 50\n","\n","noise_for_training_visualization = generate_noise(noise_dim, batch_size = 9)\n","\n","for epoch in range(EPOCHS):\n","\n","  print(\"Epoch\", epoch),\n","\n","  for step, batch in enumerate(dataset):\n","    Ld, Lg, Pr, Pf = train_step(batch)\n","\n","    if step % 10 == 0:\n","      print(\"Step {}. Ld={}, Lg={}, Pr={}, Pf={}\".format(step, Ld, Lg, Pr, Pf))\n","\n","  show_image_grid(generator(noise_for_training_visualization).numpy())\n","\n","\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E2eXD3svxD_z"},"source":["# Denne kan du bruke til å utforske generatoren!\n","\n","from ipywidgets import interact\n","\n","p1 = generate_noise(noise_dim)\n","p2 = generate_noise(noise_dim)\n","p3 = generate_noise(noise_dim)\n","\n","@interact(k1=(0, 1.0), k2=(0, 1.0))\n","def g(k1, k2):\n","    p = p1 + k1 * (p2 - p1) + k2 * (p3 - p1)\n","    show_image(generator(p).numpy())"],"execution_count":null,"outputs":[]}]}